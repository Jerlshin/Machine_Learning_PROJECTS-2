{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.random.seed(10)\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "        \n",
    "data = pd.read_csv('./Datasets/titanic_dataset/train.csv')\n",
    "\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_live = { \n",
    "    0 : 'Perished',\n",
    "    1 : 'Survived'\n",
    "}\n",
    "\n",
    "dict_sex = {\n",
    "    'male' : 0,\n",
    "    'female' : 1\n",
    "}\n",
    "\n",
    "data['Bsex'] = data['Sex'].apply(lambda x : dict_sex[x])\n",
    "\n",
    "features = data[['Pclass', 'Bsex']].to_numpy()\n",
    "labels = data['Survived'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.30)\n",
    "\n",
    "print('Training records:',Y_train.size)\n",
    "print('Test records:',Y_test.size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_act(x, der=False):\n",
    "    import numpy as np\n",
    "    \n",
    "    if (der==True) : #derivative of the sigmoid\n",
    "        f = 1/(1+ np.exp(- x))*(1-1/(1+ np.exp(- x)))\n",
    "    else : # sigmoid\n",
    "        f = 1/(1+ np.exp(- x))\n",
    "    \n",
    "    return f\n",
    "\n",
    "# We may employ the Rectifier Linear Unit (ReLU)\n",
    "def ReLU_act(x, der=False):\n",
    "    import numpy as np\n",
    "    \n",
    "    if (der == True): # the derivative of the ReLU is the Heaviside Theta\n",
    "        f = np.heaviside(x, 1)\n",
    "    else :\n",
    "        f = np.maximum(x, 0)\n",
    "    \n",
    "    return f\n",
    "\n",
    "\n",
    "# Now we are ready to define the perceptron; \n",
    "# it eats a np.array (that may be a list of features )\n",
    "def perceptron(X, act='Sigmoid'): \n",
    "    import numpy as np\n",
    "    \n",
    "    shapes = X.shape # Pick the number of (rows, columns)!\n",
    "    n= shapes[0]+shapes[1]\n",
    "    # Generating random weights and bias\n",
    "    w = 2*np.random.random(shapes) - 0.5 # We want w to be between -1 and 1\n",
    "    b = np.random.random(1)\n",
    "    \n",
    "    # Initialize the function\n",
    "    f = b[0]\n",
    "    for i in range(0, X.shape[0]-1) : # run over column elements\n",
    "        for j in range(0, X.shape[1]-1) : # run over rows elements\n",
    "            f += w[i, j]*X[i,j]/n\n",
    "    # Pass it to the activation function and return it as an output\n",
    "    if act == 'Sigmoid':\n",
    "        output = sigmoid_act(f)\n",
    "    else :\n",
    "        output = ReLU_act(f)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output with sigmoid activator:  0.7563929857268776\n",
      "Output with ReLU activator:  0.8583899920882846\n"
     ]
    }
   ],
   "source": [
    "print('Output with sigmoid activator: ', perceptron(features))\n",
    "print('Output with ReLU activator: ', perceptron(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the number of perceptron per each layer:\n",
    "p=4 # Layer 1\n",
    "q=4 # Layer 2\n",
    "\n",
    "# Set up the Learning rate\n",
    "eta =  1/623\n",
    "\n",
    "\n",
    "# 0: Random initialize the relevant data \n",
    "w1 = 2*np.random.rand(p , X_train.shape[1]) - 0.5 # Layer 1\n",
    "b1 = np.random.rand(p)\n",
    "\n",
    "w2 = 2*np.random.rand(q , p) - 0.5  # Layer 2\n",
    "b2 = np.random.rand(q)\n",
    "\n",
    "wOut = 2*np.random.rand(q) - 0.5  # Output Layer\n",
    "bOut = np.random.rand(1)\n",
    "\n",
    "mu = []\n",
    "vec_y = []\n",
    "\n",
    "# Start looping over the passengers, i.e. over I.\n",
    "\n",
    "for I in range(0, X_train.shape[0]): #loop in all the passengers:\n",
    "    \n",
    "    # 1: input the data \n",
    "    x = X_train[I]\n",
    "    \n",
    "    \n",
    "    # 2: Start the algorithm\n",
    "    \n",
    "    # 2.1: Feed forward\n",
    "    z1 = ReLU_act(np.dot(w1, x) + b1) # output layer 1 \n",
    "    z2 = ReLU_act(np.dot(w2, z1) + b2) # output layer 2\n",
    "    y = sigmoid_act(np.dot(wOut, z2) + bOut) # Output of the Output layer\n",
    "    \n",
    "    #2.2: Compute the output layer's error\n",
    "    delta_Out =  (y-Y_train[I]) * sigmoid_act(y, der=True)\n",
    "    \n",
    "    #2.3: Backpropagate\n",
    "    delta_2 = delta_Out * wOut * ReLU_act(z2, der=True) # Second Layer Error\n",
    "    delta_1 = np.dot(delta_2, w2) * ReLU_act(z1, der=True) # First Layer Error\n",
    "    \n",
    "    # 3: Gradient descent \n",
    "    wOut = wOut - eta*delta_Out*z2  # Outer Layer\n",
    "    bOut = bOut - eta*delta_Out\n",
    "    \n",
    "    w2 = w2 - eta*np.kron(delta_2, z1).reshape(q,p) # Hidden Layer 2\n",
    "    b2 = b2 - eta*delta_2\n",
    "    \n",
    "    w1 = w1 - eta*np.kron(delta_1, x).reshape(p, x.shape[0]) # Hidden Layer 1\n",
    "    b1 = b1 - eta*delta_1\n",
    "    \n",
    "    # 4. Computation of the loss function\n",
    "    mu.append((1/2)*(y-Y_train[I])**2)\n",
    "    vec_y.append(y[0])\n",
    "\n",
    "\n",
    "# Plotting the Cost function for each training data     \n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(np.arange(0, X_train.shape[0]), mu, alpha=0.3, s=4, label='mu')\n",
    "plt.title('Loss for each training data point', fontsize=20)\n",
    "plt.xlabel('Training data', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the average cost function over 10 training data\n",
    "pino = []\n",
    "for i in range(0, 9):\n",
    "    pippo = 0\n",
    "    for m in range(0, 59):\n",
    "        pippo+=vec_y[60*i+m]/60\n",
    "    pino.append(pippo)\n",
    "    \n",
    "    \n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(np.arange(0, 9), pino, alpha=1, s=10, label='error')\n",
    "plt.title('Averege Loss by epoch', fontsize=20)\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
